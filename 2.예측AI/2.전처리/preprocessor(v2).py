import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
import warnings
warnings.filterwarnings('ignore')

def load_and_clean_scf_data(file_path):
    """SCF ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ì •ì œ"""
    
    print("ğŸ“¥ ë°ì´í„° ë¡œë“œ ì¤‘...")
    df = pd.read_csv(file_path)
    print(f"ì›ë³¸ ë°ì´í„° í¬ê¸°: {df.shape}")
    
    # ì²« ë²ˆì§¸ ì»¬ëŸ¼(ì¸ë±ìŠ¤) ì œê±°
    if df.columns[0] == 'Unnamed: 0' or df.columns[0] == '':
        df = df.drop(df.columns[0], axis=1)
    
    # ì›ë³¸ SCFP2022 ë°ì´í„°ì¸ ê²½ìš° ë°”ë¡œ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±
    target_amount_columns = ['ìœ ë™ì„±ìì‚°', 'ì–‘ë„ì„±ì˜ˆê¸ˆì¦ì„œ', 'ë¹„ë¨¸ë‹ˆë§ˆì¼“í€ë“œ', 'ì£¼ì‹ë³´ìœ ', 'í‡´ì§ì¤€ë¹„ê¸ˆìœ ë™ì„±']
    has_amount_columns = any(col in df.columns for col in target_amount_columns)
    
    if has_amount_columns:
        print("ğŸ¯ SCFP2022 ì›ë³¸ ë°ì´í„° ê°ì§€ - íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± ì¤‘...")
        # ê¸ˆì•¡ ì»¬ëŸ¼ì—ì„œ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±
        target_mapping = {
            'LIQ': 'ìœ ë™ì„±ìì‚°',
            'CDS': 'ì–‘ë„ì„±ì˜ˆê¸ˆì¦ì„œ', 
            'NMMF': 'ë¹„ë¨¸ë‹ˆë§ˆì¼“í€ë“œ',
            'STOCKS': 'ì£¼ì‹ë³´ìœ ',
            'RETQLIQ': 'í‡´ì§ì¤€ë¹„ê¸ˆìœ ë™ì„±'
        }
        
        for target, amount_col in target_mapping.items():
            if amount_col in df.columns:
                df[target] = (df[amount_col] > 0).astype(int)
                holding_rate = df[target].mean()
                print(f"  âœ… {target} ({amount_col}): ë³´ìœ ìœ¨ {holding_rate*100:.1f}%")
    
    # cleaned_scf_data.csvì¸ ê²½ìš° í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
    if df.shape[1] > 100:  # ì „ì²´ ë°ì´í„°ì¸ ê²½ìš°
        print("ğŸ”§ ì „ì²´ ë°ì´í„°ì—ì„œ í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ ì¤‘...")
        
        # í•„ìš”í•œ ë…ë¦½ë³€ìˆ˜ (12ê°œ)
        feature_columns = [
            # ìµœê³  ì¤‘ìš”ë„ (4ê°œ)
            'ì—°ë ¹ëŒ€ë¶„ë¥˜', 'êµìœ¡ìˆ˜ì¤€ë¶„ë¥˜', 'ì‚¬ì—…ë†ì—…ì†Œë“', 'ìë³¸ì´ë“ì†Œë“',
            
            # ê¸°ë³¸ ë³€ìˆ˜ (4ê°œ)
            'ì—°ë ¹', 'ì´ì†Œë“', 'ê¸ˆìœµìœ„í—˜ê°ìˆ˜', 'ì €ì¶•ì—¬ë¶€',
            
            # ì¶”ê°€ ë³´ì™„ (4ê°œ)
            'ê¸‰ì—¬ì†Œë“', 'ê¸ˆìœµìœ„í—˜íšŒí”¼', 'êµìœ¡ìˆ˜ì¤€', 'ê°€êµ¬ì£¼ì„±ë³„',

            # ëª¨ë“  ìƒí’ˆì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ì¤‘ìš”í•œ ë³€ìˆ˜ë“¤ (4ê°œ)
            'ê²°í˜¼ìƒíƒœ', 'ìë…€ìˆ˜', 'ì§ì—…ë¶„ë¥˜1', 'ì´ìì‚°'
        ]
        
        # ì¢…ì†ë³€ìˆ˜ (5ê°œ) - ìƒì„±ëœ ê²ƒ ë˜ëŠ” ê¸°ì¡´ ê²ƒ
        target_columns = ['LIQ', 'CDS', 'NMMF', 'STOCKS', 'RETQLIQ']
        
        # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ í•„í„°ë§
        all_needed_columns = []
        
        for col in feature_columns + target_columns:
            if col in df.columns:
                all_needed_columns.append(col)
        
        if len(all_needed_columns) > 0:
            df = df[all_needed_columns].copy()
            print(f"ì„ íƒëœ ì»¬ëŸ¼ ìˆ˜: {len(all_needed_columns)}ê°œ")
    
    print(f"ì •ì œ í›„ ë°ì´í„° í¬ê¸°: {df.shape}")
    print(f"ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}ê°œ")
    
    return df

def check_data_quality(df):
    """ë°ì´í„° í’ˆì§ˆ í™•ì¸"""
    
    print("\nğŸ” ë°ì´í„° í’ˆì§ˆ í™•ì¸...")
    
    # ê²°ì¸¡ê°’ í™•ì¸
    missing_count = df.isnull().sum().sum()
    print(f"ì´ ê²°ì¸¡ê°’: {missing_count}ê°œ")
    
    if missing_count == 0:
        print("âœ… ê²°ì¸¡ê°’ ì—†ìŒ - ë°ì´í„° í’ˆì§ˆ ì–‘í˜¸!")
    else:
        print("âš ï¸ ê²°ì¸¡ê°’ ë°œê²¬ - ì²˜ë¦¬ í•„ìš”")
    
    # ê¸°ë³¸ í†µê³„ í™•ì¸
    print(f"\nğŸ“Š ê¸°ë³¸ ì •ë³´:")
    print(f"  - ì´ ìƒ˜í”Œ ìˆ˜: {len(df):,}ê°œ")
    print(f"  - ì´ ë³€ìˆ˜ ìˆ˜: {len(df.columns)}ê°œ")
    print(f"  - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
    
    return df

def remove_outliers(df):
    """ì´ìƒê°’ ì œê±°"""
    
    print("\nğŸš¨ ì´ìƒê°’ ì œê±° ì¤‘...")
    original_len = len(df)
    
    # ë‚˜ì´ ì´ìƒê°’ (18-100ì„¸ ë²”ìœ„)
    if 'ì—°ë ¹' in df.columns:
        df = df[(df['ì—°ë ¹'] >= 18) & (df['ì—°ë ¹'] <= 100)]
        print(f"  - ì—°ë ¹ ì´ìƒê°’ ì œê±° ì™„ë£Œ")
    
    # ì†Œë“ ì´ìƒê°’ (ìƒìœ„ 1%, í•˜ìœ„ 1% ì œê±°)
    if 'ì´ì†Œë“' in df.columns:
        income_q1 = df['ì´ì†Œë“'].quantile(0.01)
        income_q99 = df['ì´ì†Œë“'].quantile(0.99)
        df = df[(df['ì´ì†Œë“'] >= income_q1) & (df['ì´ì†Œë“'] <= income_q99)]
        print(f"  - ì´ì†Œë“ ì´ìƒê°’ ì œê±° ì™„ë£Œ")
    
    # ìì‚° ì´ìƒê°’ (ìŒìˆ˜ ì œê±°, ìƒìœ„ 1% ì œê±°)
    if 'ì´ìì‚°' in df.columns:
        asset_q99 = df['ì´ìì‚°'].quantile(0.99)
        df = df[(df['ì´ìì‚°'] >= 0) & (df['ì´ìì‚°'] <= asset_q99)]
        print(f"  - ì´ìì‚° ì´ìƒê°’ ì œê±° ì™„ë£Œ")
    
    # ìˆœìì‚° ê·¹ë‹¨ê°’ ì œê±°
    if 'ìˆœìì‚°' in df.columns:
        networth_q1 = df['ìˆœìì‚°'].quantile(0.01)
        networth_q99 = df['ìˆœìì‚°'].quantile(0.99)
        df = df[(df['ìˆœìì‚°'] >= networth_q1) & (df['ìˆœìì‚°'] <= networth_q99)]
        print(f"  - ìˆœìì‚° ì´ìƒê°’ ì œê±° ì™„ë£Œ")
    
    removed_count = original_len - len(df)
    print(f"âœ… ì´ìƒê°’ {removed_count}ê°œ ì œê±° ì™„ë£Œ ({removed_count/original_len*100:.1f}%)")
    print(f"ì •ì œ í›„ ë°ì´í„° í¬ê¸°: {df.shape}")
    
    return df

def create_derived_features(df):
    """í•„ìš”í•œ íŒŒìƒ ë³€ìˆ˜ ìƒì„±"""
    
    print("\nğŸ”§ íŒŒìƒ ë³€ìˆ˜ ìƒì„± ì¤‘...")
    
    # ì—°ë ¹ëŒ€ë¶„ë¥˜ ìƒì„± (ì—†ëŠ” ê²½ìš°)
    if 'ì—°ë ¹ëŒ€ë¶„ë¥˜' not in df.columns and 'ì—°ë ¹' in df.columns:
        df['ì—°ë ¹ëŒ€ë¶„ë¥˜'] = pd.cut(df['ì—°ë ¹'], 
                                bins=[0, 30, 40, 50, 60, 100],
                                labels=[1, 2, 3, 4, 5])
        print("  - ì—°ë ¹ëŒ€ë¶„ë¥˜ ìƒì„± ì™„ë£Œ")
    
    # êµìœ¡ìˆ˜ì¤€ë¶„ë¥˜ ìƒì„± (ì—†ëŠ” ê²½ìš°)
    if 'êµìœ¡ìˆ˜ì¤€ë¶„ë¥˜' not in df.columns and 'êµìœ¡ìˆ˜ì¤€' in df.columns:
        def map_education_level(edu_code):
            if edu_code <= 7:
                return 1  # ê³ ë“±í•™êµ ì´í•˜
            elif edu_code == 8:
                return 2  # ê³ ë“±í•™êµ ì¡¸ì—…
            elif edu_code <= 11:
                return 3  # ì „ë¬¸ëŒ€/ëŒ€í•™êµ
            else:
                return 4  # ëŒ€í•™êµ ì¡¸ì—… ì´ìƒ
        
        df['êµìœ¡ìˆ˜ì¤€ë¶„ë¥˜'] = df['êµìœ¡ìˆ˜ì¤€'].apply(map_education_level)
        print("  - êµìœ¡ìˆ˜ì¤€ë¶„ë¥˜ ìƒì„± ì™„ë£Œ")
    
    print("âœ… íŒŒìƒ ë³€ìˆ˜ ìƒì„± ì™„ë£Œ")
    
    return df

def create_target_variable(df):
    """SCFP2022 ì‹¤ì œ ê¸ˆìœµìƒí’ˆ ë³´ìœ  ë°ì´í„° ê¸°ë°˜ íƒ€ê²Ÿ ìƒì„±"""
    
    print("\nğŸ¯ ì¢…ì†ë³€ìˆ˜ ìƒì„± ì¤‘ (5ê°œ ì‹¤ì œ ê¸ˆìœµìƒí’ˆ)...")
    
    # SCFP2022ì˜ ì‹¤ì œ ê¸ˆì•¡ ì»¬ëŸ¼ëª…ì— ë§ì¶° ì¢…ì†ë³€ìˆ˜ ìƒì„±
    target_mapping = {
        'LIQ': 'ìœ ë™ì„±ìì‚°',           # ìœ ë™ì„±ìì‚° ê¸ˆì•¡ì´ 0 ì´ìƒì´ë©´ 1
        'CDS': 'ì–‘ë„ì„±ì˜ˆê¸ˆì¦ì„œ',       # ì–‘ë„ì„±ì˜ˆê¸ˆì¦ì„œ ê¸ˆì•¡ì´ 0 ì´ìƒì´ë©´ 1  
        'NMMF': 'ë¹„ë¨¸ë‹ˆë§ˆì¼“í€ë“œ',      # ë¹„ë¨¸ë‹ˆë§ˆì¼“í€ë“œ ê¸ˆì•¡ì´ 0 ì´ìƒì´ë©´ 1
        'STOCKS': 'ì£¼ì‹ë³´ìœ ',         # ì£¼ì‹ë³´ìœ  ê¸ˆì•¡ì´ 0 ì´ìƒì´ë©´ 1
        'RETQLIQ': 'í‡´ì§ì¤€ë¹„ê¸ˆìœ ë™ì„±'  # í‡´ì§ì¤€ë¹„ê¸ˆìœ ë™ì„± ê¸ˆì•¡ì´ 0 ì´ìƒì´ë©´ 1
    }
    
    print("=== íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± ê²°ê³¼ ===")
    created_targets = []
    
    for target, amount_col in target_mapping.items():
        if amount_col in df.columns:
            # ê¸ˆì•¡ì´ 0ë³´ë‹¤ í¬ë©´ 1(ë³´ìœ ), ì•„ë‹ˆë©´ 0(ë¯¸ë³´ìœ )
            df[target] = (df[amount_col] > 0).astype(int)
            
            # ë³´ìœ ìœ¨ í™•ì¸
            holding_rate = df[target].mean()
            print(f"  âœ… {target} ({amount_col}): ë³´ìœ ìœ¨ {holding_rate*100:.1f}%")
            created_targets.append(target)
        else:
            print(f"  âš ï¸ {amount_col} ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # ëŒ€ì•ˆ: ë³´ìœ ì—¬ë¶€ ì»¬ëŸ¼ ì‚¬ìš©
            backup_col = amount_col + 'ë³´ìœ ì—¬ë¶€'
            if backup_col in df.columns:
                df[target] = df[backup_col]
                holding_rate = df[target].mean()
                print(f"  âœ… {target} (ëŒ€ì•ˆ: {backup_col}): ë³´ìœ ìœ¨ {holding_rate*100:.1f}%")
                created_targets.append(target)
            else:
                print(f"      ëŒ€ì•ˆ ì»¬ëŸ¼({backup_col})ë„ ì—†ìŒ")
    
    print(f"\nìƒì„±ëœ íƒ€ê²Ÿ ë³€ìˆ˜: {len(created_targets)}ê°œ")
    return df

def prepare_ml_features(df):
    """íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ MLìš© íŠ¹ì„± ë°ì´í„° ì¤€ë¹„"""
    
    print("\nâš™ï¸ íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ML íŠ¹ì„± ë°ì´í„° ì¤€ë¹„ ì¤‘...")
    
    # 16ê°œ ë…ë¦½ë³€ìˆ˜ (ê³ ì •)
    all_features = [
        # ìµœê³  ì¤‘ìš”ë„ (4ê°œ)
        'ì—°ë ¹ëŒ€ë¶„ë¥˜', 'êµìœ¡ìˆ˜ì¤€ë¶„ë¥˜', 'ì‚¬ì—…ë†ì—…ì†Œë“', 'ìë³¸ì´ë“ì†Œë“',
        
        # ê¸°ë³¸ ë³€ìˆ˜ (4ê°œ)
        'ì—°ë ¹', 'ì´ì†Œë“', 'ê¸ˆìœµìœ„í—˜ê°ìˆ˜', 'ì €ì¶•ì—¬ë¶€',
        
        # ì¶”ê°€ ë³´ì™„ (4ê°œ)
        'ê¸‰ì—¬ì†Œë“', 'ê¸ˆìœµìœ„í—˜íšŒí”¼', 'êµìœ¡ìˆ˜ì¤€', 'ê°€êµ¬ì£¼ì„±ë³„',

        # ëª¨ë“  ìƒí’ˆì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ì¤‘ìš”í•œ ë³€ìˆ˜ë“¤ (4ê°œ)
        'ê²°í˜¼ìƒíƒœ', 'ìë…€ìˆ˜', 'ì§ì—…ë¶„ë¥˜1', 'ì´ìì‚°'
    ]
    
    # 5ê°œ ì¢…ì†ë³€ìˆ˜ (ê³ ì •)
    target_features = ['LIQ', 'CDS', 'NMMF', 'STOCKS', 'RETQLIQ']
    
    # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
    available_features = [col for col in all_features if col in df.columns]
    missing_features = [col for col in all_features if col not in df.columns]
    available_targets = [col for col in target_features if col in df.columns]
    
    # íŠ¹ì„± ë°ì´í„°ì™€ íƒ€ê²Ÿ ë°ì´í„° ë¶„ë¦¬
    if len(available_features) > 0:
        X = df[available_features].copy()
    else:
        print("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ë…ë¦½ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤!")
        X = pd.DataFrame()
    
    y_dict = {}
    for target in available_targets:
        y_dict[target] = df[target].copy()
    
    print(f"âœ… ì„ íƒëœ íŠ¹ì„± ë³€ìˆ˜: {len(available_features)}ê°œ")
    if missing_features:
        print(f"âš ï¸ ëˆ„ë½ëœ íŠ¹ì„± ë³€ìˆ˜: {len(missing_features)}ê°œ")
    print(f"âœ… íƒ€ê²Ÿ ë³€ìˆ˜: {len(available_targets)}ê°œ")
    print(f"âœ… ìƒ˜í”Œ ìˆ˜: {len(X)}ê°œ")
    
    if missing_features:
        print(f"\nâš ï¸ ëˆ„ë½ëœ íŠ¹ì„± ë³€ìˆ˜:")
        for feature in missing_features:
            print(f"  - {feature}")
    
    print(f"\nğŸ“Š ì‚¬ìš©ëœ íŠ¹ì„± ë³€ìˆ˜:")
    for i, feature in enumerate(available_features):
        print(f"  {i+1}. {feature}")
    
    print(f"\nğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ (5ê°œ ì‹¤ì œ ê¸ˆìœµìƒí’ˆ):")
    product_names = {
        'LIQ': 'ìœ ë™ì„±ìì‚°',
        'CDS': 'ì–‘ë„ì„±ì˜ˆê¸ˆì¦ì„œ', 
        'NMMF': 'ë¹„ë¨¸ë‹ˆë§ˆì¼“í€ë“œ',
        'STOCKS': 'ì£¼ì‹ë³´ìœ ',
        'RETQLIQ': 'í‡´ì§ì¤€ë¹„ê¸ˆìœ ë™ì„±'
    }
    
    for target in available_targets:
        holding_rate = df[target].mean() if target in df.columns else 0
        product_name = product_names.get(target, target)
        print(f"  - {product_name} ({target}): {holding_rate:.1%}")
    
    return X, y_dict, available_features

def encode_categorical_variables(df):
    """SCFP2022 ë°ì´í„°ì— ë§ëŠ” ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬"""
    
    print("\nğŸ”¤ ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬ ì¤‘...")
    
    # SCFP2022ëŠ” ëŒ€ë¶€ë¶„ ìˆ˜ì¹˜í˜• ì½”ë“œë¡œ ë˜ì–´ìˆìœ¼ë¯€ë¡œ Tree-based ëª¨ë¸ì— ì í•©
    # í•„ìš”í•œ ì „ì²˜ë¦¬ë§Œ ìˆ˜í–‰
    
    processed_count = 0
    
    # ì—°ë ¹ëŒ€ë¶„ë¥˜ í™•ì¸ ë° ì •ë¦¬
    if 'ì—°ë ¹ëŒ€ë¶„ë¥˜' in df.columns:
        df['ì—°ë ¹ëŒ€ë¶„ë¥˜'] = df['ì—°ë ¹ëŒ€ë¶„ë¥˜'].astype(int)
        processed_count += 1
    
    # êµìœ¡ìˆ˜ì¤€ë¶„ë¥˜ í™•ì¸ ë° ì •ë¦¬
    if 'êµìœ¡ìˆ˜ì¤€ë¶„ë¥˜' in df.columns:
        df['êµìœ¡ìˆ˜ì¤€ë¶„ë¥˜'] = df['êµìœ¡ìˆ˜ì¤€ë¶„ë¥˜'].astype(int)
        processed_count += 1
    
    print(f"âœ… ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬ ì™„ë£Œ: {processed_count}ê°œ")
    print("  - ëŒ€ë¶€ë¶„ ìˆ˜ì¹˜í˜• ì½”ë“œë¡œ ìœ ì§€ (Tree-based ëª¨ë¸ì— ì í•©)")
    
    return df, {}

def data_summary(df, X, y_dict):
    """ë°ì´í„° ìš”ì•½ ì •ë³´ ì¶œë ¥"""
    
    print("\nğŸ“Š ìµœì¢… ë°ì´í„° ìš”ì•½")
    print("=" * 60)
    print(f"ì´ ìƒ˜í”Œ ìˆ˜: {len(df):,}ê°œ")
    print(f"ì´ ë³€ìˆ˜ ìˆ˜: {len(df.columns)}ê°œ")
    print(f"ë…ë¦½ë³€ìˆ˜ ìˆ˜: {len(X.columns)}ê°œ")
    print(f"íƒ€ê²Ÿë³€ìˆ˜ ìˆ˜: {len(y_dict)}ê°œ")
    
    print("\nì£¼ìš” í†µê³„:")
    summary_cols = ['ì—°ë ¹', 'ì´ì†Œë“', 'ì´ìì‚°', 'ìˆœìì‚°']
    for col in summary_cols:
        if col in df.columns:
            print(f"  {col}: í‰ê·  {df[col].mean():.0f}, ì¤‘ì•™ê°’ {df[col].median():.0f}")
    
    print("\níƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬:")
    for target, target_data in y_dict.items():
        pos_rate = target_data.mean()
        print(f"  {target}: {pos_rate:.1%} ë³´ìœ ")
    
    print("\në©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:")
    print(f"  ì „ì²´ ë°ì´í„°: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
    print(f"  ë…ë¦½ë³€ìˆ˜: {X.memory_usage(deep=True).sum() / 1024**2:.1f} MB")

def main_preprocessing_pipeline(file_path):
    """ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
    
    print("ğŸš€ SCF ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘!")
    print("=" * 60)
    
    try:
        # 1. ë°ì´í„° ë¡œë“œ (ì—¬ê¸°ì„œ SCFP2022 ì›ë³¸ì´ë©´ íƒ€ê²Ÿ ë³€ìˆ˜ë„ ìë™ ìƒì„±)
        df = load_and_clean_scf_data(file_path)
        
        # 2. ë°ì´í„° í’ˆì§ˆ í™•ì¸
        df = check_data_quality(df)
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ê°€ ìˆëŠ”ì§€ í™•ì¸
        target_exists = any(col in df.columns for col in ['LIQ', 'CDS', 'NMMF', 'STOCKS', 'RETQLIQ'])
        
        if not target_exists:
            print("\nğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ê°€ ì—†ì–´ì„œ ì¶”ê°€ ì²˜ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤!")
            
            # 3. ì´ìƒê°’ ì œê±°
            df = remove_outliers(df)
            
            # 4. íŒŒìƒ ë³€ìˆ˜ ìƒì„±
            df = create_derived_features(df)
            
            # 5. ì¢…ì†ë³€ìˆ˜ ìƒì„± (í•„ìš”í•œ ê²½ìš°ë§Œ)
            df = create_target_variable(df)
            
            # 6. ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬
            df, encoders = encode_categorical_variables(df)
        else:
            print("\nâœ… íƒ€ê²Ÿ ë³€ìˆ˜ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤!")
            # ê°„ë‹¨í•œ ì²˜ë¦¬ë§Œ ìˆ˜í–‰
            df = remove_outliers(df)
            df = create_derived_features(df)
            df, encoders = encode_categorical_variables(df)
        
        # 7. MLìš© íŠ¹ì„± ì¤€ë¹„
        X, y_dict, feature_names = prepare_ml_features(df)
        
        # 8. ë°ì´í„° ìš”ì•½
        data_summary(df, X, y_dict)
        
        print("\nâœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")
        
        return df, X, y_dict, feature_names, encoders
        
    except Exception as e:
        print(f"\nâŒ ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise e

# ì‹¤í–‰ ì˜ˆì‹œ
if __name__ == "__main__":
    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    file_path = "data/SCFP/SCFP2022_í•œê¸€.csv"
    
    try:
        # ì „ì²˜ë¦¬ ì‹¤í–‰
        print("ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘...")
        cleaned_df, X, y_dict, features, encoders = main_preprocessing_pipeline(file_path)
        
        # ê²°ê³¼ í™•ì¸
        print("\nğŸ“Š ìµœì¢… ê²°ê³¼:")
        print(f"ë…ë¦½ë³€ìˆ˜: {len(features)}ê°œ")
        print(f"íƒ€ê²Ÿë³€ìˆ˜: {len(y_dict)}ê°œ")
        print(f"ìƒ˜í”Œ ìˆ˜: {len(X)}ê°œ")
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ë³„ ë³´ìœ ìœ¨ ì¶œë ¥
        print("\nğŸ¯ ìƒí’ˆë³„ ë³´ìœ ìœ¨:")
        for target, target_data in y_dict.items():
            print(f"  {target}: {target_data.mean():.1%}")
        
        # ê²°ê³¼ ì €ì¥ (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œ)
        cleaned_df.to_csv("data/SCFP/cleaned_scf_data.csv", index=False, encoding='utf-8')
        print("\nğŸ’¾ ì •ì œëœ ë°ì´í„°ê°€ 'cleaned_scf_data.csv'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        # ê¸°ì¡´ ë³€ìˆ˜ëª… í˜¸í™˜ì„ ìœ„í•´ y_dictë¥¼ yë¡œ ë³€í™˜ (ì„ íƒì‚¬í•­)
        y = y_dict  # ë˜ëŠ” í•„ìš”ì— ë”°ë¼ íŠ¹ì • íƒ€ê²Ÿë§Œ ì„ íƒ
        
        # ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´
#        print("\nğŸ”„ ë‹¤ìŒ ë‹¨ê³„:")
#        print("1. Random Forest ëª¨ë¸ í•™ìŠµ")
#        print("2. íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„")
#        print("3. ëª¨ë¸ ì„±ëŠ¥ í‰ê°€")
#        print("4. Django API êµ¬ì¶•")
        
    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        print("íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print("ë°ì´í„° íŒŒì¼ì˜ í˜•ì‹ì´ë‚˜ ì»¬ëŸ¼ëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")